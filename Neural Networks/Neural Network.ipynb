{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"https://iamtrask.github.io/2015/07/12/basic-python-network/\">A Tiny Neural Network</a>\n",
       "\n",
       "Consider trying to predict the output column given the three input columns. We could solve this problem by simply measuring statistics between the input values and the output values. If we did so, we would see that the leftmost input column is perfectly correlated with the output. Backpropagation, in its simplest form, measures statistics like this to make a model. Let's jump right in and use it to do this."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<a href=\"https://iamtrask.github.io/2015/07/12/basic-python-network/\">A Tiny Neural Network</a>\n",
    "\n",
    "Consider trying to predict the output column given the three input columns. We could solve this problem by simply measuring statistics between the input values and the output values. If we did so, we would see that the leftmost input column is perfectly correlated with the output. Backpropagation, in its simplest form, measures statistics like this to make a model. Let's jump right in and use it to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<center>\n",
       "<style type=\"text/css\">\n",
       ".tg  {border-collapse:collapse;border-spacing:0;border-color:#ccc;}\n",
       ".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#ccc;color:#333;background-color:#fff;}\n",
       ".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#ccc;color:#333;background-color:#f0f0f0;}\n",
       ".tg .tg-5rcs{font-weight:bold;font-size:20px;}\n",
       ".tg .tg-4kyz{font-size:20px;text-align:center;}\n",
       "</style>\n",
       "<table class=\"tg\">\n",
       "  <tbody><tr>\n",
       "    <th class=\"tg-5rcs\" colspan=\"3\">Inputs</th>\n",
       "    <th class=\"tg-5rcs\">Output</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"tg-4kyz\">0</td>\n",
       "    <td class=\"tg-4kyz\">0</td>\n",
       "    <td class=\"tg-4kyz\">1</td>\n",
       "    <td class=\"tg-4kyz\">0</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"tg-4kyz\">1</td>\n",
       "    <td class=\"tg-4kyz\">1</td>\n",
       "    <td class=\"tg-4kyz\">1</td>\n",
       "    <td class=\"tg-4kyz\">1</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"tg-4kyz\">1</td>\n",
       "    <td class=\"tg-4kyz\">0</td>\n",
       "    <td class=\"tg-4kyz\">1</td>\n",
       "    <td class=\"tg-4kyz\">1</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"tg-4kyz\">0</td>\n",
       "    <td class=\"tg-4kyz\">1</td>\n",
       "    <td class=\"tg-4kyz\">1</td>\n",
       "    <td class=\"tg-4kyz\">0</td>\n",
       "  </tr>\n",
       "</tbody></table>\n",
       "</center>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "%%html\n",
    "<center>\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;border-color:#ccc;}\n",
    ".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#ccc;color:#333;background-color:#fff;}\n",
    ".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#ccc;color:#333;background-color:#f0f0f0;}\n",
    ".tg .tg-5rcs{font-weight:bold;font-size:20px;}\n",
    ".tg .tg-4kyz{font-size:20px;text-align:center;}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "  <tbody><tr>\n",
    "    <th class=\"tg-5rcs\" colspan=\"3\">Inputs</th>\n",
    "    <th class=\"tg-5rcs\">Output</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-4kyz\">0</td>\n",
    "    <td class=\"tg-4kyz\">0</td>\n",
    "    <td class=\"tg-4kyz\">1</td>\n",
    "    <td class=\"tg-4kyz\">0</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-4kyz\">1</td>\n",
    "    <td class=\"tg-4kyz\">1</td>\n",
    "    <td class=\"tg-4kyz\">1</td>\n",
    "    <td class=\"tg-4kyz\">1</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-4kyz\">1</td>\n",
    "    <td class=\"tg-4kyz\">0</td>\n",
    "    <td class=\"tg-4kyz\">1</td>\n",
    "    <td class=\"tg-4kyz\">1</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-4kyz\">0</td>\n",
    "    <td class=\"tg-4kyz\">1</td>\n",
    "    <td class=\"tg-4kyz\">1</td>\n",
    "    <td class=\"tg-4kyz\">0</td>\n",
    "  </tr>\n",
    "</tbody></table>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output After Training:\n",
      "[[ 0.00966449]\n",
      " [ 0.00786506]\n",
      " [ 0.99358898]\n",
      " [ 0.99211957]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# sigmoid function\n",
    "def nonlin(x,deriv=False):\n",
    "    if(deriv==True):\n",
    "        return x*(1-x)\n",
    "    return 1/(1+np.exp(-x))\n",
    "    \n",
    "# input dataset\n",
    "X = np.array([  [0,0,1],\n",
    "                [0,1,1],\n",
    "                [1,0,1],\n",
    "                [1,1,1] ])\n",
    "    \n",
    "# output dataset            \n",
    "y = np.array([[0,0,1,1]]).T\n",
    "\n",
    "# seed random numbers to make calculation\n",
    "# deterministic (just a good practice)\n",
    "np.random.seed(1)\n",
    "\n",
    "# initialize weights randomly with mean 0\n",
    "syn0 = 2*np.random.random((3,1)) - 1\n",
    "\n",
    "for iter in xrange(10000):\n",
    "\n",
    "    # forward propagation\n",
    "    layer0 = X\n",
    "    layer1 = nonlin(np.dot(layer0,syn0))\n",
    "\n",
    "    # how much did we miss?\n",
    "    layer1_error = y - l1\n",
    "\n",
    "    # multiply how much we missed by the \n",
    "    # slope of the sigmoid at the values in l1\n",
    "    layer1_delta = layer1_error * nonlin(layer1,True)\n",
    "\n",
    "    # update weights\n",
    "    syn0 += np.dot(layer0.T,layer1_delta)\n",
    "\n",
    "print \"Output After Training:\"\n",
    "print l1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<tbody><tr>\n",
       "    <th class=\"tg-5rcs\" colspan=\"1\">Variable</th>\n",
       "    <th class=\"tg-5rcs\">Definition</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"tg-4kyx\">X</td>\n",
       "    <td class=\"tg-4kyz\">Input dataset matrix where each row is a training example</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"tg-4kyx\">y</td>\n",
       "    <td class=\"tg-4kyz\">Output dataset matrix where each row is a training example</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"tg-4kyx\">l0</td>\n",
       "    <td class=\"tg-4kyz\">First Layer of the Network, specified by the input data</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"tg-4kyx\">l1</td>\n",
       "    <td class=\"tg-4kyz\">Second Layer of the Network, otherwise known as the hidden layer</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"tg-4kyx\">syn0</td>\n",
       "    <td class=\"tg-4kyz\">First layer of weights, Synapse 0, connecting l0 to l1.</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"tg-4kyx\">*</td>\n",
       "    <td class=\"tg-4kyz\">Elementwise multiplication, so two vectors of equal size are multiplying corresponding values 1-to-1 to generate a final vector of identical size.</td>\n",
       "  </tr>\n",
       "  \n",
       "    <tr>\n",
       "    <td class=\"tg-4kyx\">-</td>\n",
       "    <td class=\"tg-4kyz\">Elementwise subtraction, so two vectors of equal size are subtracting corresponding values 1-to-1 to generate a final vector of identical size.</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"tg-4kyx\">x.dot(y)</td>\n",
       "    <td class=\"tg-4kyz\">If x and y are vectors, this is a dot product. If both are matrices, it's a matrix-matrix multiplication. If only one is a matrix, then it's vector matrix multiplication.</td>\n",
       "  </tr>\n",
       "</tbody>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "\n",
    "<tbody><tr>\n",
    "    <th class=\"tg-5rcs\" colspan=\"1\">Variable</th>\n",
    "    <th class=\"tg-5rcs\">Definition</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-4kyx\">X</td>\n",
    "    <td class=\"tg-4kyz\">Input dataset matrix where each row is a training example</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-4kyx\">y</td>\n",
    "    <td class=\"tg-4kyz\">Output dataset matrix where each row is a training example</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-4kyx\">l0</td>\n",
    "    <td class=\"tg-4kyz\">First Layer of the Network, specified by the input data</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-4kyx\">l1</td>\n",
    "    <td class=\"tg-4kyz\">Second Layer of the Network, otherwise known as the hidden layer</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-4kyx\">syn0</td>\n",
    "    <td class=\"tg-4kyz\">First layer of weights, Synapse 0, connecting l0 to l1.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-4kyx\">*</td>\n",
    "    <td class=\"tg-4kyz\">Elementwise multiplication, so two vectors of equal size are multiplying corresponding values 1-to-1 to generate a final vector of identical size.</td>\n",
    "  </tr>\n",
    "  \n",
    "    <tr>\n",
    "    <td class=\"tg-4kyx\">-</td>\n",
    "    <td class=\"tg-4kyz\">Elementwise subtraction, so two vectors of equal size are subtracting corresponding values 1-to-1 to generate a final vector of identical size.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-4kyx\">x.dot(y)</td>\n",
    "    <td class=\"tg-4kyz\">If x and y are vectors, this is a dot product. If both are matrices, it's a matrix-matrix multiplication. If only one is a matrix, then it's vector matrix multiplication.</td>\n",
    "  </tr>\n",
    "</tbody>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<tbody><tr>\n",
       "    <th class=\"tg-5rcs\" colspan=\"1\">Variable</th>\n",
       "    <th class=\"tg-5rcs\">Definition</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"tg-4kyx\">X</td>\n",
       "    <td class=\"tg-4kyz\">Input dataset matrix where each row is a training example</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"tg-4kyx\">y</td>\n",
       "    <td class=\"tg-4kyz\">Output dataset matrix where each row is a training example</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"tg-4kyx\">l0</td>\n",
       "    <td class=\"tg-4kyz\">First Layer of the Network, specified by the input data</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"tg-4kyx\">l1</td>\n",
       "    <td class=\"tg-4kyz\">Second Layer of the Network, otherwise known as the hidden layer</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"tg-4kyx\">l2</td>\n",
       "    <td class=\"tg-4kyz\">Final Layer of the Network, which is our hypothesis, and should approximate the correct answer as we train.</td>\n",
       "  </tr>\n",
       "    <tr>\n",
       "    <td class=\"tg-4kyx\">syn0</td>\n",
       "    <td class=\"tg-4kyz\">First layer of weights, Synapse 0, connecting l0 to l1.</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"tg-4kyx\">syn1</td>\n",
       "    <td class=\"tg-4kyz\">Second layer of weights, Synapse 1 connecting l1 to l2.</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"tg-4kyx\">l2_error</td>\n",
       "    <td class=\"tg-4kyz\">This is the amount that the neural network \"missed\".</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"tg-4kyx\">l2_delta</td>\n",
       "    <td class=\"tg-4kyz\">This is the error of the network scaled by the confidence. It's almost identical to the error except that very confident errors are muted.</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"tg-4kyx\">l1_error</td>\n",
       "    <td class=\"tg-4kyz\">Weighting l2_delta by the weights in syn1, we can calculate the error in the middle/hidden layer.</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"tg-4kyx\">l1_delta</td>\n",
       "    <td class=\"tg-4kyz\">This is the l1 error of the network scaled by the confidence. Again, it's almost identical to the l1_error except that confident errors are muted.</td>\n",
       "  </tr>\n",
       "</tbody>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "\n",
    "<tbody><tr>\n",
    "    <th class=\"tg-5rcs\" colspan=\"1\">Variable</th>\n",
    "    <th class=\"tg-5rcs\">Definition</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-4kyx\">X</td>\n",
    "    <td class=\"tg-4kyz\">Input dataset matrix where each row is a training example</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-4kyx\">y</td>\n",
    "    <td class=\"tg-4kyz\">Output dataset matrix where each row is a training example</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-4kyx\">l0</td>\n",
    "    <td class=\"tg-4kyz\">First Layer of the Network, specified by the input data</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-4kyx\">l1</td>\n",
    "    <td class=\"tg-4kyz\">Second Layer of the Network, otherwise known as the hidden layer</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-4kyx\">l2</td>\n",
    "    <td class=\"tg-4kyz\">Final Layer of the Network, which is our hypothesis, and should approximate the correct answer as we train.</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td class=\"tg-4kyx\">syn0</td>\n",
    "    <td class=\"tg-4kyz\">First layer of weights, Synapse 0, connecting l0 to l1.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-4kyx\">syn1</td>\n",
    "    <td class=\"tg-4kyz\">Second layer of weights, Synapse 1 connecting l1 to l2.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-4kyx\">l2_error</td>\n",
    "    <td class=\"tg-4kyz\">This is the amount that the neural network \"missed\".</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-4kyx\">l2_delta</td>\n",
    "    <td class=\"tg-4kyz\">This is the error of the network scaled by the confidence. It's almost identical to the error except that very confident errors are muted.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-4kyx\">l1_error</td>\n",
    "    <td class=\"tg-4kyz\">Weighting l2_delta by the weights in syn1, we can calculate the error in the middle/hidden layer.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-4kyx\">l1_delta</td>\n",
    "    <td class=\"tg-4kyz\">This is the l1 error of the network scaled by the confidence. Again, it's almost identical to the l1_error except that confident errors are muted.</td>\n",
    "  </tr>\n",
    "</tbody>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:0.496410031903\n",
      "Error:0.00858452565325\n",
      "Error:0.00578945986251\n",
      "Error:0.00462917677677\n",
      "Error:0.00395876528027\n",
      "Error:0.00351012256786\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def nonlin(x,deriv=False):\n",
    "\tif(deriv==True):\n",
    "\t    return x*(1-x)\n",
    "\n",
    "\treturn 1/(1+np.exp(-x))\n",
    "    \n",
    "X = np.array([[0,0,1],\n",
    "            [0,1,1],\n",
    "            [1,0,1],\n",
    "            [1,1,1]])\n",
    "                \n",
    "y = np.array([[0],\n",
    "\t\t\t[1],\n",
    "\t\t\t[1],\n",
    "\t\t\t[0]])\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "# randomly initialize our weights with mean 0\n",
    "syn0 = 2*np.random.random((3,4)) - 1\n",
    "syn1 = 2*np.random.random((4,1)) - 1\n",
    "\n",
    "for j in xrange(60000):\n",
    "\n",
    "\t# Feed forward through layers 0, 1, and 2\n",
    "    l0 = X\n",
    "    l1 = nonlin(np.dot(l0,syn0))\n",
    "    l2 = nonlin(np.dot(l1,syn1))\n",
    "\n",
    "    # how much did we miss the target value?\n",
    "    l2_error = y - l2\n",
    "    \n",
    "    if (j% 10000) == 0:\n",
    "        print \"Error:\" + str(np.mean(np.abs(l2_error)))\n",
    "        \n",
    "    # in what direction is the target value?\n",
    "    # were we really sure? if so, don't change too much.\n",
    "    l2_delta = l2_error*nonlin(l2,deriv=True)\n",
    "\n",
    "    # how much did each l1 value contribute to the l2 error (according to the weights)?\n",
    "    l1_error = l2_delta.dot(syn1.T)\n",
    "    \n",
    "    # in what direction is the target l1?\n",
    "    # were we really sure? if so, don't change too much.\n",
    "    l1_delta = l1_error * nonlin(l1,deriv=True)\n",
    "\n",
    "    syn1 += l1.T.dot(l2_delta)\n",
    "    syn0 += l0.T.dot(l1_delta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
